
########################################################################
#   Lab 4 -- Large Vocabulary Decoding: A Love Story
#   EECS E6870: Speech Recognition
#   Due: Friday, April 1, 2016 at 6:00pm
########################################################################

* Name: Jingyi Yuan


########################################################################
#   Part 1
########################################################################

* Create a single FSA "p1a.fsm" that represents the strings "I LIKE BEARS"
  and "BEARS I LIKE".  Turn this into an FST by running the command

      FsmOp p1a.fsm -make-transducer p1a.fst

  List "p1a.fsm" below.

->
# states: 7
# input-voc: /dynamic/
1	2	I
2	3	LIKE
3	4	BEARS
1	5	BEARS
5	6	I
6	7	LIKE
7
4


* Create an FST "p1b.fst" with a single state that rewrites all word sequences
  (containing only the words I, LIKE, and BEARS) to themselves except
  that the word "LIKE" is changed to "LOVE".  List "p1b.fst" below.

->
# states: 1
# input-voc: /dynamic/
# output-voc: /dynamic/
# transducer:true
1	1	I	I
1	1	BEARS	BEARS
1	1	LIKE	LOVE
1


* Compose the FST "p1a.fst" and the FST "p1b.fst" via the command

      FsmOp p1a.fst p1b.fst -compose p1c.fst
      
  and look at the resulting FSM "p1c.fst".  While we did not cover
  FST/FST composition in class, can you describe how FST/FST composition
  behaves?  If it helps, you can create more example FSM's for yourself and
  use "FsmOp" to see how things behave.

->
p1c.fst is:
# states: 7
# input-voc: /dynamic/
# output-voc: /dynamic/
1	2	I	I
1	3	BEARS	BEARS
2	4	LIKE	LOVE
3	5	I	I
4	6	BEARS	BEARS
5	7	LIKE	LOVE
6
7

It is the same as FSA FST composition. We took the input of first FST and use the same way as FSA/FST composition.


* Look at the provided FSM "p1d.fsm".  Using only your FSM "p1a.fsm",
  the provided FSM "p1d.fsm", and "FsmOp", create an FSM that
  represents all three-word strings (containing only the words I, LIKE,
  and BEARS) *except* for the strings "I LIKE BEARS" and "BEARS I LIKE".
  (This should include three-word strings with repeated words, e.g., "I I I".)
  You will need to use the operations "-concat", "-determinize",
  and "-difference" in "FsmOp".  Run "FsmOp" with no arguments
  to get a little help on these commands.  To find out more
  about what these commands do, just make sample FSM's and run "FsmOp"
  on them.  NOTE: for the "-difference" operation to work correctly, the
  input FSM's must be determinized.  Put the resulting FSM in "p1e.fsm".
  To check whether this FSM is correct, run
  "FsmOp p1e.fsm -gen" to print all strings this FSM accepts.
  List the commands you executed to create "p1e.fsm" (you need
  not submit any files for Part 1):

->
FsmOp p1d.fsm p1d.fsm -concat p1d.fsm -concat p1a.fsm -difference > p1e.fsm


########################################################################
#   Part 2
########################################################################

* In the example in the lab write-up, the first thing we do
  is convert "wd.fsm" from an acceptor into a transducer.
  Why do we do this, i.e., in what way would the final graph
  be lacking if we were to keep the graph an acceptor the whole
  way and used the same expansion recipe given in the example?

->
For a transducer, each arc has two symbols: an input label and an output label. It accepts a string pair. We can use composition to apply FST to FSA. If we keep the graph an accepter, we will not have the composition, thus we do not have transform set of strings. Some 1:many and 1:0 transforms cannot be expressed. We cannot replace arbitrary strings with arbitrary strings. We cannot do context-dependent transforms. The complete output cannot be expressed compactly.


* Edit the FSM's "wd2lx.fsm" and "lx2pn.fsm" so that they can
  handle an additional word in the vocabulary: BRITNEY,
  with a single pronunciation variant:

      BRITNEY(01)    | B R IH TD N IY

  To test them, expand the word FSM "wd3.fsm" containing the
  string "I LIKE BRITNEY" to the phone level using these transducers.

  Submit the files "wd2lx.fsm" and "lx2pn.fsm" by typing
  the following command (in the directory ~/e6870/lab4/):

      submit-e6870.py lab4 wd2lx.fsm lx2pn.fsm

  More generally, the usage of "submit-e6870.py" is as follows:

      submit-e6870.py <lab#> <file1> <file2> <file3> ...

  You can submit a file multiple times; later submissions
  will overwrite earlier ones.  Submissions will fail
  if the destination directory for you has not been created
  for the given <lab#>; contact us if this happens.


* On slide 59 of lecture 9, we present an FST that can optionally
  insert any number of silences between words (over the vocabulary
  {A, B, C}).  Can you make an FST "addsil.fsm" that will optionally insert
  at most one silence between words (and at the beginning and end of
  an utterance), for the vocabulary {I, LIKE, BRITNEY}?
  To test this, compose this with "wd3.fsm" to create the file "wd3sil.fsm".
  You can look at "wd3sil.target.fsm" to see what the
  target "wd3sil.fsm" looks like.  (Note that it's possible to create
  equivalent FSM's that look quite different; e.g., if you renumber the
  states in an FSM, the FSM will still have the same semantics.)

  Submit "addsil.fsm":

      submit-e6870.py lab4 addsil.fsm


* Examine the file "tree.txt".  What
  type of decision-tree is this, i.e., triphone, quinphone, etc.?

->
Triphone. Each phone is composed of 3 parts. It contains +-1 phones of context.


* For the phone IH in BRITNEY, manually compute which
  leaves correspond to each of its three states by
  examining the corresponding decision trees in "tree.txt".

->
IH_1: 149
IH_2: 152
IH_3: 155


* In the file "small_lm.fsm", identify the index of the state
  corresponding to the unigram backoff state, i.e., the state corresponding
  to the one labeled with "epsilon" on slide 86 of lecture 9.
  (Hint: there is exactly one such state in the whole graph.):

->
state 1


* In the file "small_graph.fsm", will there also be a unique
  unigram backoff state?  Why or why not?

->
No. It is an inverted graph and except for words and silence, all other states uses epsilon as the output. The graph is not compact.


* If we run determinization on "small_lm.fsm", we will run out of memory
  because the resulting FSM is very, very large.  Can you explain
  why this happens?  (Hint: The key is in the <epsilon> backoff arcs.
  What will a typical state set in determinization look like, and
  what will be its outgoing arcs.
  Hint: Will the number of states increase a lot,
  the number of arcs increase a lot, or both?)
  (This is one reason why LVCSR decoders need to handle skip arcs,
  because trying to optimize these out will make graphs much larger.)

->
The backoff state will make the determinization have a lot of trigrams, which will increase the number of both states and arcs a lot. This will largely increase the memory cost.

########################################################################
#   Part 3
########################################################################

* Instead of using a heap to iterate through active states in order at
  each frame, another idea is to sort all active cells in "curFrame" by
  state number at the beginning of processing each frame.  Why does sorting
  all of the cells beforehand not completely address the handling of skip arcs?

->
All skip arcs go from lower-numbered states to higher-numbered states. When using a heap, the method get_next_state() does iterate through states in increasing order, keeps track of all cells not yet iterated through and always returns the cell corresponding to the lowest-numbered state (we have to be able to handle new cells being inserted into the current frame as we are looping through the cells in the current frame). But when sorting active cells, we can only go to the next cell, which may not be the lowest-numbered state. Also, we have to take newly inserted cells into consideration while looping through the cells. Thus may not completely address the handling of skip arcs.


* Create the file "p3b.out" containing the output of
  running "lab4_p3b.sh" (i.e., run "lab4_p3b.sh | tee p3b.out").
  Create the file "p3d.out" containing the output of
  running "lab4_p3d.sh" (i.e., run "lab4_p3d.sh | tee p3d.out").
  Submit the following files:

      submit-e6870.py lab4 p3b.out p3d.out


########################################################################
#   Part 4
########################################################################

* The Viterbi algorithm attempts to identify the most likely complete path
  through an HMM given some data.  When using pruning, it is possible
  that no complete paths are found at all.  Describe how to detect
  when this has happened.  When not using pruning, is it also possible
  that no complete paths are found?  Why or why not?

->
When using pruning, we compute the threshold by taking the highest log probability of any cell at that frame and subtracting the beam width. Before processing the outgoing arcs of a state in the main loop, we first check whether its log probability is above the threshold. If in this frame, we have all cur.Cell.get_log_prob() < threshold, i.e., we have only the cell with highest log probability, then all states in this frame is skipped thus no complete path will be found. We can detect it by adding a sign in the while loop. If any state is processed, we set the sign to be 1, and if all states are skipped, we keep it to be 0. When entering the next loop, if sign is 0, we know that all states in the last frame is skipped. When not using pruning, it is not possible that no complete paths are found since we go through all states, expect that the graph itself is wrong.


* Create the file "p4b.out" containing the output of
  running "lab4_p4b.sh" (i.e., run "lab4_p4b.sh | tee p4b.out").
  Submit this file as well as your source code, e.g.,

      submit-e6870.py lab4 lab4_vit.C p4b.out

  Don't forget to submit your source code!!  (If you implemented
  rank pruning, make sure the version of the source code you
  submit includes this.)


* If you implemented rank pruning, create "p4c.out" and
  "p4d.out" by running "lab4_p4c.sh | tee p4c.out" and
  "lab4_p4d.sh | tee p4d.out".  Submit these files:

      submit-e6870.py lab4 p4c.out p4d.out

  Describe what algorithm you used to find the rank pruning
  threshold:

->
I set the threshold to be the log prob of the cell int he current frame with the k-th highest log prob. To do this, I use a vector to record all the log prob of the cell and return k-th (beamStateCnt-th) highest after sorting the vector. By adding the loop, I can get the k-th highest log prob and when pruning, I change the if sentence to be if (curCell.get_log_prob() < threshold || curCell.get_log_prob() < highestProb) continue; to implement rank pruning.


########################################################################
#   Part 5
########################################################################

* What word-error rates and real-time factors did you find for the
  following conditions?
  (Examine the file "p5.out" to extract this information.)

->
WSJ decoding, beam = 3: 28.12%
WSJ decoding, beam = 5: 15.10%
WSJ decoding, beam = 10: 15.10%

WSJ decoding, 3k voc, small LM, beam = 7: 15.10%
WSJ decoding, 21k voc, small LM, beam = 7: 16.15%
WSJ decoding, 21k voc, large LM, beam = 7: 12.50%


* What fraction of the time was spend on front end vs. GMM probs vs.
  Viterbi search for the following conditions?
  (Examine the file "p5.out" to extract this information.)

->
isolated digit decoding: 42.3% front end; 56.3% GMM; 0.0% search
WSJ decoding, 21k voc, large LM, beam = 7: 0.0% front end; 27.0% GMM; 73.0% search


* What did you learn in this part?

->
As the number of beams increases, the word-error rates decreases. For this lab, when beam is larger than 5, the word-error rate converges. Second, using large size LM instead of small lM also make word-error rates decreases while increasing vocabulary size may slightly increase word-error rates. Third, isolated digit decoding spends more time on front end and GMM while WSJ decoding spend more time on Viterbi search and front end.


########################################################################
#   Wrap Up
########################################################################

After filling in all of the fields in this file, submit this file
using the following command:

    submit-e6870.py lab4 lab4.txt

The timestamp on the last submission of this file (if you submit
multiple times) will be the one used to determine your official
submission time (e.g., for figuring out if you handed in the
assignment on time).

To verify whether your files were submitted correctly, you can
use the command:

    check-e6870.py lab4

This will list all of the files in your submission directory,
along with file sizes and submission times.


########################################################################
#
########################################################################


