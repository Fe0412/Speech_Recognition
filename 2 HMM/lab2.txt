
########################################################################
#   Lab 2: HMM's and You
#   EECS E6870: Speech Recognition
#   Due: February 26, 2016 at 6pm
########################################################################

* Name:Jingyi Yuan


########################################################################
#   Part 1
########################################################################

* Some people put HMM output distributions on states (e.g., in the readings)
  and some people put HMM output distributions on arcs (e.g., the slides
  and the lab).  Are these two representations equivalent, e.g., can
  they express the same set of models?  Can you think of any
  advantage one representation might have over the other?

->As the reading suggests, in forward algorithm, the number inside each cell indicates the forward probability, thus the algorithm will be calculated in a more direct way. And in Viterbi algorithm, the number inside each cell indicates the best score and the best path leading to each cell is indicated by solid line. As the slides and lab show, the distributions are on arcs so that we can clearly see the probability from one state to another with an exact output. These two representations are equivalent and we can get output distribution on states through those on arcs. Putting HMM output on arcs may be more easy to understand can all datas can be seen when we are dealing with them.


* When doing isolated word recognition, one method is to compute the
  likelihood of the acoustic feature vectors with each word HMM separately,
  and then to pick the word HMM with the highest likelihood.
  Another method is to use the "one big HMM" paradigm and
  to use the Viterbi algorithm and traceback to select the best word.
  Are these methods equivalent (in terms of the answer selected)?
  Why or why not?

->Yes they are equivalent. We use Viterbi so that we can collect all words along the way while doing backtrace (but we cannot use forward algorithm). But when move to word sequences, one big graph cannot have HMM for each sequence since it prunes during the process and can only fill k best cells at each frame. Generally, the backtrace is same, but the graph is different.


* To do the dynamic programming computation correctly, one must
  iterate through the cells in the dynamic programming chart
  in an order that satisfies the following property:
  when filling in a cell, all cells that the cell
  depends on must already be filled in.  Consider the following
  two orderings for filling the DP chart:

      (1) for (int frmIdx = 0; frmIdx < frmCnt; ++frmIdx)
            for (int stateIdx = 0; stateIdx < stateCnt; ++stateIdx)
              fill_DP_cell(frmIdx + 1, stateIdx);

      (2) for (int stateIdx = 0; stateIdx < stateCnt; ++stateIdx)
            for (int frmIdx = 0; frmIdx < frmCnt; ++frmIdx)
              fill_DP_cell(frmIdx + 1, stateIdx);

  If there are no skip arcs, which one of these orderings will always
  produce the correct result regardless of HMM topology?  Describe
  a situation where the other ordering can give the wrong answer.
  If there are skip arcs, under what conditions is the good ordering
  still valid?

->The first ordering will always produce the correct result. Since the frame come in sequence, it would be better for us to do dynamic programming frame by frame and use the previous state to fill in the cell in the next frame. Only by doing this can we ensure that when filling in a cell, all cells that the cell depends on must already be filled in. For example in the big HMM in this part, if we use the second method, the result will me wrong since we first initialing the first row. If we going through the first column first, the first column will all maintain to be g_zeroLogProb even if there is a cell to be filled in. If there are skip arcs, there should be other arc that can reach this cell to ensure the method to be still valid.


* Create the file "p1b.out" by running:

      lab2_p1b.sh | tee p1b.out

  Submit the following files:

      submit-e6870.py lab2 lab2_vit.C p1b.out

  More generally, the usage of "submit-e6870.py" is as follows:

      submit-e6870.py <lab#> <file1> <file2> <file3> ...

  You can submit a file multiple times; later submissions
  will overwrite earlier ones.  Submissions will fail
  if the destination directory for you has not been created
  for the given <lab#>; contact us if this happens.


########################################################################
#   Part 2
########################################################################

* Create the file "p2b.gmm" by running "lab2_p2b.sh".
  Submit the following files:

      submit-e6870.py lab2 gmm_util.C p2b.gmm


* In this lab, we assumed all GMM's were composed of a single Gaussian.
  When GMM's are composed of multiple Gaussians, each component Gaussian
  of the mixture is updated in essentially the same way as before,
  except we need to figure out the correct posterior counts to use.
  Explain how to compute the posterior count of each component Gaussian
  given the posterior count of the entire GMM.

->It is like what we do in the Expectation in EM algorithm(P(h|xi) = P(h, xi)/sum(P(h,xi))). Since posterior is joint probability distribution divided by marginal probability distribution, it is distributed as the product of prior and likelihood. Thus if we know the prior and the mean and variance in the previous iteration, we can calculate by multiply the prior and the pdf of this Gaussian distribution. We use this product to be divided by he posterior count of the entire GMM, and the result is the posterior count of this component Gaussian.



* Given the total posterior counts of each Gaussian in a GMM, explain
  how to reestimate the mixture weights of each Gaussian in that GMM.

->Like what we do in the maximization step(Ph = sum(P(h|xi))/N), we sum the posterior count of each data point xi and divide it by the total number of data points in this model, we will get the mixture weights of each Gaussian in that GMM.


########################################################################
#   Part 3
########################################################################

* Create the file "p3c.out" containing the output of
  running "lab2_p3c.sh" (i.e., run "lab2_p3c.sh | tee p3c.out").
  Submit the following files:

      submit-e6870.py lab2 lab2_fb.C p3c.out


########################################################################
#   Part 4
########################################################################

* What word-error rates did you find by running "lab2_p4a.sh"?

->4.00%


* What word-error rates did you find by running "lab2_p4b.sh"?

->21.10%


* What word-error rates did you find by running "lab2_p4c.sh"?

->32.00%


* What did you learn in this part?

->Comparing part4 a and part 4 b, we know that the error rate of decoding connected digit string data is higher than that of isolated digits, that is, the digit may be influence by other digits(before or behind it) like what we do in our daily life. Comparing the result of part4 a and part4 c, we know that when we include trained transition probabilities int the big HMM, the error rate increases sharply. That is it is better to ignore transition probabilities in big HMM.


* If an HMM were a fruit, what type of fruit would it be?

->I guess it would be watermelon. We have to decide the one that has the max likelihood to be a tasty watermelon by seeing only the outside part of it. That it is like choosing the most probable hidden states and path giving the output.


########################################################################
#   Wrap Up
########################################################################

After filling in all of the fields in this file, submit this file
using the following command:

    submit-e6870.py lab2 lab2.txt

The timestamp on the last submission of this file (if you submit
multiple times) will be the one used to determine your official
submission time (e.g., for figuring out if you handed in the
assignment on time).

To verify whether your files were submitted correctly, you can
use the command:

    check-e6870.py lab2

This will list all of the files in your submission directory,
along with file sizes and submission times.


########################################################################
#
########################################################################


